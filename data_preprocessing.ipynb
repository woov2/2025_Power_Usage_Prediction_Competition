{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e65d7cb9-40e9-49cc-8e97-4b78a8bfe7fe",
   "metadata": {},
   "source": [
    "## Library version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Python & library version --------------------------\n",
      "Python version: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:13) \n",
      "[Clang 14.0.6 ]\n",
      "pandas version: 1.5.3\n",
      "numpy version: 1.23.5\n",
      "matplotlib version: 3.7.0\n",
      "tqdm version: 4.64.1\n",
      "sktime version: 0.16.1\n",
      "lightgbm version: 4.3.0\n",
      "seaborn version: 0.13.2\n",
      "scikit-learn version: 1.2.2\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sktime\n",
    "import tqdm as tq\n",
    "import lightgbm as lgb\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b5e25e-f9a1-4980-ac53-6cdb73b3d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.utils.plotting import plot_series\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82dc3d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 461.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "info = pd.read_csv('./data/building_info.csv')\n",
    "\n",
    "\n",
    "#Ï†ÑÎ†•ÏÜåÎπÑÎüâ Ïù¥ÏÉÅÏπò Ï≤òÎ¶¨(Í±¥Î¨ºÎ≤àÌò∏Î•º Í∏∞Ï§Ä)\n",
    "for num in tqdm(range(train['Í±¥Î¨ºÎ≤àÌò∏'].nunique())):\n",
    "    train.loc[train['Í±¥Î¨ºÎ≤àÌò∏'] == num+1, 'Ï†ÑÎ†•ÏÜåÎπÑÎüâ(kWh)'] = train.loc[train['Í±¥Î¨ºÎ≤àÌò∏'] == num+1, 'Ï†ÑÎ†•ÏÜåÎπÑÎüâ(kWh)'].clip(train.loc[train['Í±¥Î¨ºÎ≤àÌò∏'] == num+1, 'Ï†ÑÎ†•ÏÜåÎπÑÎüâ(kWh)'].quantile(.03), train.loc[train['Í±¥Î¨ºÎ≤àÌò∏'] == num+1, 'Ï†ÑÎ†•ÏÜåÎπÑÎüâ(kWh)'].quantile(.97))\n",
    "\n",
    "info = info.iloc[:,:4]\n",
    "train = train.merge(info,on='Í±¥Î¨ºÎ≤àÌò∏',how='left')\n",
    "test = test.merge(info,on='Í±¥Î¨ºÎ≤àÌò∏',how='left')\n",
    "\n",
    "## Î≥ÄÏàòÎì§ÏùÑ ÏòÅÎ¨∏Î™ÖÏúºÎ°ú Î≥ÄÍ≤Ω\n",
    "cols = ['num_date_time', 'build_num', 'date_time', 'temp' ,'prec', 'wind', 'hum', 'isolation', 'sunshine', 'power','use', 'area_1', 'area_2']\n",
    "train.columns = cols\n",
    "\n",
    "def summer_cos(date):\n",
    "    start_date = datetime.strptime(\"2024-06-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date = datetime.strptime(\"2024-09-14 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    period = (end_date - start_date).total_seconds()\n",
    "\n",
    "    return math.cos(2 * math.pi * (date - start_date).total_seconds() / period)\n",
    "\n",
    "def summer_sin(date):\n",
    "    start_date = datetime.strptime(\"2024-06-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date = datetime.strptime(\"2024-09-14 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    period = (end_date - start_date).total_seconds()\n",
    "\n",
    "    return math.sin(2 * math.pi * (date - start_date).total_seconds() / period)\n",
    "\n",
    "# ÏãúÍ∞Ñ Í¥ÄÎ†® Î≥ÄÏàòÎì§ ÏÉùÏÑ±\n",
    "date = pd.to_datetime(train.date_time)\n",
    "train['date_time'] = pd.to_datetime(train['date_time'])\n",
    "train['date'] = date.dt.date\n",
    "train['hour'] = date.dt.hour\n",
    "train['day'] = date.dt.day\n",
    "train['weekday'] = date.dt.weekday\n",
    "train['month'] = date.dt.month\n",
    "\n",
    "train.loc[13238:13826, 'power'] += 3500\n",
    "train.loc[19161:20343, 'power'] -= 4000\n",
    "train = train.drop(index=range(114240, 114408))\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f559d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_interpolate_building_power(df, targets, target_col='power', method='time'):\n",
    "    \"\"\"\n",
    "    Ïó¨Îü¨ Í±¥Î¨º/ÏãúÏ†ê(Îã®Ïùº or Íµ¨Í∞Ñ)Ïóê ÎåÄÌï¥ ÏãúÍ∞Ñ Í∏∞Î∞ò Î≥¥Í∞ÑÏùÑ Ìïú Î≤àÏóê Ï†ÅÏö©ÌïòÎäî Ìï®Ïàò.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "        targets (list of tuples): \n",
    "            [(build_num, start_time), (build_num, start_time, end_time), ...] ÌòïÌÉúÏùò Î¶¨Ïä§Ìä∏\n",
    "            - end_timeÏù¥ ÏóÜÏúºÎ©¥ Îã®Ïùº ÏãúÏ†ê Ï≤òÎ¶¨\n",
    "        target_col (str): Î≥¥Í∞ÑÌï† Ïª¨ÎüºÎ™Ö\n",
    "        method (str): pandas.interpolate method\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Î≥¥Í∞ÑÏù¥ Ï†ÅÏö©Îêú ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "    \"\"\"\n",
    "    for item in targets:\n",
    "        # ÌäúÌîå Í∏∏Ïù¥Ïóê Îî∞Îùº Îã®Ïùº ÏãúÏ†ê/Íµ¨Í∞Ñ Ï≤òÎ¶¨\n",
    "        if len(item) == 2:\n",
    "            build_num, start_time = item\n",
    "            end_time = None\n",
    "        elif len(item) == 3:\n",
    "            build_num, start_time, end_time = item\n",
    "        else:\n",
    "            raise ValueError(\"targetsÎäî (build_num, start_time) ÎòêÎäî (build_num, start_time, end_time) ÌòïÏãùÏù¥Ïñ¥Ïïº Ìï©ÎãàÎã§.\")\n",
    "\n",
    "        # ÎåÄÏÉÅ Í±¥Î¨º Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú\n",
    "        building = df[df['build_num'] == build_num].sort_values('date_time').copy()\n",
    "\n",
    "        # Í≤∞Ï∏° Ï≤òÎ¶¨\n",
    "        if end_time is None:\n",
    "            mask_missing = (building['date_time'] == pd.Timestamp(start_time))\n",
    "        else:\n",
    "            mask_missing = (\n",
    "                (building['date_time'] >= pd.Timestamp(start_time)) &\n",
    "                (building['date_time'] <= pd.Timestamp(end_time))\n",
    "            )\n",
    "        building.loc[mask_missing, target_col] = np.nan\n",
    "\n",
    "        # ÏãúÍ∞Ñ Í∏∞Î∞ò Î≥¥Í∞Ñ\n",
    "        building.set_index('date_time', inplace=True)\n",
    "        building[target_col] = building[target_col].interpolate(method=method)\n",
    "        building.reset_index(inplace=True)\n",
    "\n",
    "        # ÏõêÎ≥∏ Î∞òÏòÅ\n",
    "        df.loc[df['build_num'] == build_num, target_col] = building[target_col].values\n",
    "\n",
    "    return df\n",
    "\n",
    "targets = [\n",
    "    (3, '2024-07-17 14:00'),\n",
    "    (7, '2024-08-06 03:00'),\n",
    "    (18, '2024-07-17 14:00'),\n",
    "    (30, '2024-07-13 20:00'),\n",
    "    (30, '2024-07-25 00:00'),\n",
    "    (42, '2024-07-17 14:00'),\n",
    "    (47, '2024-07-17 14:00'),\n",
    "    (55, '2024-07-17 14:00'),\n",
    "    (76, '2024-08-22 21:00'),\n",
    "    (81, '2024-06-27 14:00'),\n",
    "    (81, '2024-07-17 14:00'),\n",
    "    (82, '2024-07-17 14:00'),\n",
    "    (83, '2024-07-17 14:00'), \n",
    "    (5, '2024-08-04 06:00', '2024-08-04 08:00'), \n",
    "    (18, '2024-06-11 17:00', '2024-06-11 18:00'), \n",
    "    (18, '2024-08-08 15:00', '2024-08-08 16:00'), \n",
    "    (28, '2024-07-17 14:00', '2024-07-17 15:00'), \n",
    "    (38, '2024-07-17 14:00', '2024-07-17 15:00'), \n",
    "    (41, '2024-07-17 09:00', '2024-07-17 15:00'), \n",
    "    (60, '2024-07-17 14:00', '2024-07-17 15:00'), \n",
    "    (62, '2024-07-17 13:00', '2024-07-17 15:00'), \n",
    "    (69, '2024-07-17 14:00', '2024-07-17 15:00'),  \n",
    "    (76, '2024-06-20 12:00', '2024-06-20 16:00'),  \n",
    "    (78, '2024-07-17 13:00', '2024-07-17 14:00'),\n",
    "\n",
    "    # (81, '2024-07-25 13:00', '2024-07-25 17:00'), \n",
    "    # (81, '2024-07-26 13:00', '2024-07-26 17:00'), \n",
    "    # (81, '2024-07-29 13:00', '2024-07-29 17:00'), \n",
    "    # (81, '2024-07-30 13:00', '2024-07-30 17:00'), \n",
    "    # (81, '2024-08-01 13:00', '2024-08-01 17:00'), \n",
    "    # (81, '2024-08-02 13:00', '2024-08-02 17:00'), \n",
    "    # (81, '2024-08-05 13:00', '2024-08-05 17:00'), \n",
    "    # (81, '2024-08-06 13:00', '2024-08-06 16:00'), \n",
    "    # (81, '2024-08-07 13:00', '2024-08-07 17:00'), \n",
    "    # (81, '2024-08-09 13:00', '2024-08-09 17:00'), \n",
    "\n",
    "    # (81, '2024-08-12 10:00', '2024-08-12 15:00'), \n",
    "    # (81, '2024-08-13 13:00', '2024-08-13 17:00'), \n",
    "    # (81, '2024-08-14 10:00', '2024-08-14 17:00'), \n",
    "    # (81, '2024-08-16 10:00', '2024-08-16 17:00'), \n",
    "    # (81, '2024-08-19 10:00', '2024-08-19 17:00'), \n",
    "    # (81, '2024-08-23 11:00', '2024-08-23 16:00'), \n",
    "\n",
    "    (89, '2024-07-12 08:00', '2024-07-12 10:00'), \n",
    "    (97, '2024-07-17 13:00', '2024-07-17 15:00'), \n",
    "]\n",
    "\n",
    "train = batch_interpolate_building_power(train, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c12a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÍµêÏ≤¥Ìï† Í±¥Î¨ºÍ≥º Í∏∞Í∞Ñ\n",
    "build_num = 17\n",
    "target_start = pd.Timestamp(\"2024-06-25 15:00\")\n",
    "target_end = pd.Timestamp(\"2024-06-26 09:00\")\n",
    "\n",
    "# Î≥µÏÇ¨Ìï† ÏõêÎ≥∏ Ìå®ÌÑ¥ (Ï†Ñ Ï£º ÎèôÏùº Íµ¨Í∞Ñ)\n",
    "source_start = target_start - pd.Timedelta(days=7)\n",
    "source_end = target_end - pd.Timedelta(days=7)\n",
    "\n",
    "# ÎßàÏä§ÌÅ¨\n",
    "mask_source = (\n",
    "    (train['build_num'] == build_num) &\n",
    "    (train['date_time'] >= source_start) &\n",
    "    (train['date_time'] <= source_end)\n",
    ")\n",
    "mask_target = (\n",
    "    (train['build_num'] == build_num) &\n",
    "    (train['date_time'] >= target_start) &\n",
    "    (train['date_time'] <= target_end)\n",
    ")\n",
    "\n",
    "# Ìå®ÌÑ¥ Ï∂îÏ∂ú\n",
    "pattern_data = train.loc[mask_source].sort_values('date_time')['power'].values\n",
    "target_indices = train.loc[mask_target].sort_values('date_time').index\n",
    "\n",
    "# Í∏∏Ïù¥ ÎßûÏ∂∞ÏÑú ÎçÆÏñ¥Ïì∞Í∏∞\n",
    "length = min(len(pattern_data), len(target_indices))\n",
    "train.loc[target_indices[:length], 'power'] = pattern_data[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed71787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_apply_pattern_scaling(df, tasks, target_col='power'):\n",
    "    \"\"\"\n",
    "    Ïó¨Îü¨ Ìå®ÌÑ¥ Î≥µÏÇ¨ ÏûëÏóÖÏùÑ Ìïú Î≤àÏóê Ï≤òÎ¶¨.\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "        tasks (list of tuples): \n",
    "            [\n",
    "                (build_num, source_start, source_end, value_start, value_end, target_start, target_end),\n",
    "                ...\n",
    "            ]\n",
    "        target_col (str): ÏàòÏ†ïÌï† Ïª¨ÎüºÎ™Ö\n",
    "    Returns:\n",
    "        pd.DataFrame: ÏàòÏ†ïÎêú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "    \"\"\"\n",
    "    for build_num, source_start, source_end, value_start_time, value_end_time, target_start, target_end in tasks:\n",
    "        # 1. ÏõêÎ≥∏ Ìå®ÌÑ¥ Ï∂îÏ∂ú\n",
    "        pattern_mask = (\n",
    "            (df['build_num'] == build_num) &\n",
    "            (df['date_time'] >= pd.Timestamp(source_start)) &\n",
    "            (df['date_time'] <= pd.Timestamp(source_end))\n",
    "        )\n",
    "        P_source = df.loc[pattern_mask].sort_values('date_time')[target_col].values\n",
    "        if len(P_source) == 0:\n",
    "            continue  # Ìå®ÌÑ¥ ÏóÜÏúºÎ©¥ Ïä§ÌÇµ\n",
    "\n",
    "        # 2. ÏãúÏûë/Ï¢ÖÎ£å Í∞í\n",
    "        V_start = df.loc[\n",
    "            (df['build_num'] == build_num) & (df['date_time'] == pd.Timestamp(value_start_time)),\n",
    "            target_col\n",
    "        ].values[0]\n",
    "        V_end = df.loc[\n",
    "            (df['build_num'] == build_num) & (df['date_time'] == pd.Timestamp(value_end_time)),\n",
    "            target_col\n",
    "        ].values[0]\n",
    "\n",
    "        # 3. Ï†ïÍ∑úÌôî Î∞è Ïä§ÏºÄÏùºÎßÅ\n",
    "        P_min, P_max = P_source.min(), P_source.max()\n",
    "        P_scaled = (P_source - P_min) / (P_max - P_min + 1e-8)\n",
    "        P_target = V_start + (V_end - V_start) * P_scaled\n",
    "\n",
    "        # 4. ÎåÄÏÉÅ Íµ¨Í∞Ñ Ïù∏Îç±Ïä§\n",
    "        target_mask = (\n",
    "            (df['build_num'] == build_num) &\n",
    "            (df['date_time'] >= pd.Timestamp(target_start)) &\n",
    "            (df['date_time'] <= pd.Timestamp(target_end))\n",
    "        )\n",
    "        target_indices = df.loc[target_mask].sort_values('date_time').index\n",
    "\n",
    "        # 5. Í∏∏Ïù¥ ÎßûÏ∂∞ ÏÇΩÏûÖ\n",
    "        length = min(len(P_target), len(target_indices))\n",
    "        df.loc[target_indices[:length], target_col] = P_target[:length]\n",
    "\n",
    "    return df\n",
    "\n",
    "tasks = [\n",
    "    (7, '2024-06-30 10:00', '2024-07-01 11:00', '2024-07-07 09:00', '2024-07-08 12:00', '2024-07-07 10:00', '2024-07-08 11:00'),\n",
    "    (7, '2024-07-05 14:00', '2024-07-05 23:00', '2024-07-12 13:00', '2024-07-13 00:00', '2024-07-12 14:00', '2024-07-12 23:00'),\n",
    "    # (17, '2024-06-18 15:00', '2024-06-19 09:00', '2024-06-25 14:00', '2024-06-26 10:00', '2024-06-25 15:00', '2024-06-26 09:00')\n",
    "]\n",
    "\n",
    "train = batch_apply_pattern_scaling(train, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d42492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_fill_hourly_means(df, tasks, target_col='power'):\n",
    "    \"\"\"\n",
    "    Ïó¨Îü¨ Í±¥Î¨º/Í∏∞Í∞Ñ/ÏãúÍ∞ÑÎåÄ ÌèâÍ∑†ÏùÑ Îã§Î•∏ ÎÇ†ÏßúÎ°ú ÏÇΩÏûÖÌïòÎäî Î∞∞Ïπò Ìï®Ïàò.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "        tasks (list of tuples): \n",
    "            [\n",
    "                (build_num, source_dates, source_hours, target_date),\n",
    "                ...\n",
    "            ]\n",
    "            - source_dates: ('start_date','end_date') or ['date1','date2',...]\n",
    "            - source_hours: [hour1, hour2, ...]\n",
    "            - target_date: Îã®Ïùº ÎÇ†Ïßú\n",
    "        target_col (str): ÏàòÏ†ïÌï† Ïª¨ÎüºÎ™Ö (Í∏∞Î≥∏ 'power')\n",
    "    Returns:\n",
    "        pd.DataFrame: ÏàòÏ†ïÎêú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "    \"\"\"\n",
    "    for build_num, source_dates, source_hours, target_date in tasks:\n",
    "        building = df[df['build_num'] == build_num].copy()\n",
    "\n",
    "        # ÎÇ†Ïßú ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±\n",
    "        if isinstance(source_dates, (tuple, list)) and len(source_dates) == 2 and not isinstance(source_dates[0], (pd.Timestamp, str)):\n",
    "            # Î≤îÏúÑÏùº Í≤ΩÏö∞\n",
    "            start_date, end_date = pd.to_datetime(source_dates[0]).date(), pd.to_datetime(source_dates[1]).date()\n",
    "            mask_range = (\n",
    "                (building['date_time'].dt.date >= start_date) &\n",
    "                (building['date_time'].dt.date <= end_date) &\n",
    "                (building['date_time'].dt.hour.isin(source_hours))\n",
    "            )\n",
    "        else:\n",
    "            # ÎÇ†Ïßú Î¶¨Ïä§Ìä∏Ïùº Í≤ΩÏö∞\n",
    "            date_list = [pd.to_datetime(d).date() for d in source_dates]\n",
    "            mask_range = (\n",
    "                (building['date_time'].dt.date.isin(date_list)) &\n",
    "                (building['date_time'].dt.hour.isin(source_hours))\n",
    "            )\n",
    "\n",
    "        # ÏãúÍ∞ÑÎ≥Ñ ÌèâÍ∑† Í≥ÑÏÇ∞\n",
    "        hourly_means = (\n",
    "            building[mask_range]\n",
    "            .groupby(building['date_time'].dt.hour)[target_col]\n",
    "            .mean()\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        # ÌÉÄÍ≤ü ÎÇ†ÏßúÏóê ÏÇΩÏûÖ\n",
    "        for hour, mean_val in hourly_means.items():\n",
    "            mask_fill = (\n",
    "                (df['build_num'] == build_num) &\n",
    "                (df['date_time'].dt.date == pd.to_datetime(target_date).date()) &\n",
    "                (df['date_time'].dt.hour == hour)\n",
    "            )\n",
    "            df.loc[mask_fill, target_col] = mean_val\n",
    "\n",
    "    return df\n",
    "\n",
    "tasks = [\n",
    "    (67, ('2024-06-03', '2024-06-07'), [16, 17, 18], '2024-06-10'),          # 6/3~6/7 Ïò§ÌõÑ 4~6Ïãú ÌèâÍ∑† ‚Üí 6/10\n",
    "    (67, ('2024-07-29', '2024-07-31'), [15, 16], '2024-08-01'),              # 7/29~7/31 Ïò§ÌõÑ 3~4Ïãú ÌèâÍ∑† ‚Üí 8/1\n",
    "    (67, ['2024-08-13', '2024-08-14', '2024-08-16'], [16, 17], '2024-08-12'), # 8/13,14,16 Ïò§ÌõÑ 4~5Ïãú ÌèâÍ∑† ‚Üí 8/12\n",
    "    (80, ('2024-07-01', '2024-07-05'), [11,12,13,14,19,20], '2024-07-08')    # 7/1~7/5 11~14Ïãú,19~20Ïãú ÌèâÍ∑† ‚Üí 7/8\n",
    "]\n",
    "\n",
    "train = batch_fill_hourly_means(train, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c4241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_power_segments(train: pd.DataFrame, segments: list):\n",
    "    \"\"\"\n",
    "    Ï£ºÏñ¥ÏßÑ Íµ¨Í∞ÑÏùò power Í∞íÏùÑ ÏïûÎí§ ÌïòÎ£® Í∞ôÏùÄ ÏãúÍ∞ÑÎåÄ min-max Ïä§ÏºÄÏùºÎ°ú Î≥¥Ï†ï.\n",
    "    Î≥¥Ï†ïÎêú Í∞íÏùÄ train['power']Ïóê ÎçÆÏñ¥ÏîåÏõÄ.\n",
    "\n",
    "    Parameters:\n",
    "        train (pd.DataFrame): 'build_num', 'date_time', 'power' Ïª¨Îüº Ìè¨Ìï® Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "        segments (list): [(build_num, start_datetime, end_datetime), ...] ÌòïÏãùÏùò ÌäúÌîå Î¶¨Ïä§Ìä∏\n",
    "    Returns:\n",
    "        pd.DataFrame: Î≥¥Ï†ïÎêú train Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "    \"\"\"\n",
    "    train['date_time'] = pd.to_datetime(train['date_time'])\n",
    "    \n",
    "    for build_num, start_str, end_str in segments:\n",
    "        target_start = pd.Timestamp(start_str)\n",
    "        target_end = pd.Timestamp(end_str)\n",
    "\n",
    "        # ÎåÄÏÉÅ Í±¥Î¨º Îç∞Ïù¥ÌÑ∞\n",
    "        building_data = train[train['build_num'] == build_num].sort_values(by='date_time')\n",
    "        target_mask = (building_data['date_time'] >= target_start) & (building_data['date_time'] <= target_end)\n",
    "        \n",
    "        # Ï∞∏Ï°∞ Íµ¨Í∞Ñ: ÏïûÎí§ ÌïòÎ£® ÎèôÏùº ÏãúÍ∞ÑÎåÄ\n",
    "        ref_mask = (\n",
    "            ((building_data['date_time'] >= target_start - pd.Timedelta(days=1)) & (building_data['date_time'] <= target_end - pd.Timedelta(days=1))) |\n",
    "            ((building_data['date_time'] >= target_start + pd.Timedelta(days=1)) & (building_data['date_time'] <= target_end + pd.Timedelta(days=1)))\n",
    "        )\n",
    "        ref_data = building_data.loc[ref_mask, 'power']\n",
    "        if ref_data.empty:\n",
    "            continue  # Ï∞∏Ï°∞ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏúºÎ©¥ Ïä§ÌÇµ\n",
    "\n",
    "        ref_min, ref_max = ref_data.min(), ref_data.max()\n",
    "        target_data = building_data.loc[target_mask, 'power']\n",
    "        if target_data.empty or target_data.max() == target_data.min():\n",
    "            continue  # ÎåÄÏÉÅ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÍ±∞ÎÇò Î≥ÄÎèôÏù¥ ÏóÜÏúºÎ©¥ Ïä§ÌÇµ\n",
    "\n",
    "        # Ïä§ÏºÄÏùº Ï°∞Ï†ï\n",
    "        scaled = (target_data - target_data.min()) / (target_data.max() - target_data.min())  # 0~1 Ï†ïÍ∑úÌôî\n",
    "        scaled = scaled * (ref_max - ref_min) + ref_min\n",
    "\n",
    "        # trainÏóê ÎçÆÏñ¥Ïì∞Í∏∞\n",
    "        train.loc[target_mask & (train['build_num'] == build_num), 'power'] = scaled\n",
    "\n",
    "    return train\n",
    "\n",
    "segments = [\n",
    "    (30, '2024-06-20 06:00', '2024-06-20 23:00'),\n",
    "    (30, '2024-07-06 06:00', '2024-07-06 23:00'),\n",
    "]\n",
    "\n",
    "train = scale_power_segments(train, segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6f75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_weekly_pattern(train: pd.DataFrame, build_num: int, start_str: str, end_str: str):\n",
    "    \"\"\"\n",
    "    ÌäπÏ†ï Íµ¨Í∞ÑÏùÑ ÏïûÏ£º+Îã§ÏùåÏ£º ÎèôÏùº ÏãúÍ∞Å Îç∞Ïù¥ÌÑ∞ ÌèâÍ∑†ÏúºÎ°ú Ï±ÑÏö∞Í≥† train['power']Ïóê ÎçÆÏñ¥ÏîÄ.\n",
    "    \"\"\"\n",
    "    train['date_time'] = pd.to_datetime(train['date_time'])\n",
    "    building_data = train[train['build_num'] == build_num].sort_values(by='date_time')\n",
    "\n",
    "    # ÎåÄÏÉÅ Íµ¨Í∞Ñ\n",
    "    target_start = pd.Timestamp(start_str)\n",
    "    target_end = pd.Timestamp(end_str)\n",
    "    target_mask = (building_data['date_time'] >= target_start) & (building_data['date_time'] <= target_end)\n",
    "    target_range = building_data.loc[target_mask, ['date_time']].copy()\n",
    "    if target_range.empty:\n",
    "        print(f\"‚ö†Ô∏è ÎåÄÏÉÅ Íµ¨Í∞Ñ({start_str}~{end_str}) Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå\")\n",
    "        return train\n",
    "\n",
    "    # ÏïûÏ£º & Îã§ÏùåÏ£º ÎèôÏùº ÏãúÍ∞Å Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "    week_offset = pd.Timedelta(days=7)\n",
    "    ref1 = building_data.set_index('date_time').loc[target_start - week_offset : target_end - week_offset, ['power']].reset_index()\n",
    "    ref2 = building_data.set_index('date_time').loc[target_start + week_offset : target_end + week_offset, ['power']].reset_index()\n",
    "\n",
    "    # Îëê Ï£º Ìå®ÌÑ¥ align (Í∏∏Ïù¥Í∞Ä Îã§Î•º Í≤ΩÏö∞ Î≥¥Ï†ï)\n",
    "    if len(ref1) != len(target_range):\n",
    "        ref1 = ref1.reindex(range(len(target_range)), method='nearest')\n",
    "    if len(ref2) != len(target_range):\n",
    "        ref2 = ref2.reindex(range(len(target_range)), method='nearest')\n",
    "\n",
    "    # Îëê Ï£º ÌèâÍ∑† Ìå®ÌÑ¥ ÏÉùÏÑ±\n",
    "    ref_mean = (ref1['power'].values + ref2['power'].values) / 2\n",
    "    target_range['power_filled'] = ref_mean\n",
    "\n",
    "    # ÎçÆÏñ¥Ïì∞Í∏∞\n",
    "    for idx, row in target_range.iterrows():\n",
    "        train.loc[\n",
    "            (train['build_num'] == build_num) & (train['date_time'] == row['date_time']),\n",
    "            'power'\n",
    "        ] = row['power_filled']\n",
    "\n",
    "    return train\n",
    "\n",
    "# 7Ïõî 20Ïùº 02Ïãú ~ 7Ïõî 22Ïùº 10Ïãú, Í±¥Î¨º 49\n",
    "train = fill_with_weekly_pattern(\n",
    "    train, \n",
    "    build_num=43, \n",
    "    start_str=\"2024-07-20 02:00\", \n",
    "    end_str=\"2024-07-22 10:00\"\n",
    ")\n",
    "\n",
    "train = fill_with_weekly_pattern(\n",
    "    train, \n",
    "    build_num=53, \n",
    "    start_str=\"2024-06-14 16:00\", \n",
    "    end_str=\"2024-06-17 09:00\"\n",
    ")\n",
    "\n",
    "train = fill_with_weekly_pattern(\n",
    "    train, \n",
    "    build_num=67, \n",
    "    start_str=\"2024-07-27 00:00\", \n",
    "    end_str=\"2024-07-28 00:00\"\n",
    ")\n",
    "\n",
    "train = fill_with_weekly_pattern(\n",
    "    train, \n",
    "    build_num=94, \n",
    "    start_str=\"2024-07-27 00:00\", \n",
    "    end_str=\"2024-07-28 00:00\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da0b0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_value_to_segment(train: pd.DataFrame, build_num: int, start_str: str, end_str: str, add_value: float):\n",
    "    \"\"\"\n",
    "    ÌäπÏ†ï Í±¥Î¨ºÏùò ÏßÄÏ†ï Íµ¨Í∞ÑÏóê ÏùºÏ†ï Í∞íÏùÑ ÎçîÌï¥ train['power']Ïóê ÎçÆÏñ¥ÏîÄ.\n",
    "    \"\"\"\n",
    "    train['date_time'] = pd.to_datetime(train['date_time'])\n",
    "    target_start = pd.Timestamp(start_str)\n",
    "    target_end = pd.Timestamp(end_str)\n",
    "\n",
    "    mask = (\n",
    "        (train['build_num'] == build_num) &\n",
    "        (train['date_time'] >= target_start) &\n",
    "        (train['date_time'] <= target_end)\n",
    "    )\n",
    "\n",
    "    train.loc[mask, 'power'] = train.loc[mask, 'power'] + add_value\n",
    "    return train\n",
    "\n",
    "train = add_value_to_segment(\n",
    "    train,\n",
    "    build_num=53,\n",
    "    start_str=\"2024-08-18 16:00\",\n",
    "    end_str=\"2024-08-19 07:00\",\n",
    "    add_value=400\n",
    ")\n",
    "\n",
    "train = add_value_to_segment(\n",
    "    train,\n",
    "    build_num=67,\n",
    "    start_str=\"2024-06-01 00:00\",\n",
    "    end_str=\"2024-06-03 09:00\",\n",
    "    add_value=780\n",
    ")\n",
    "\n",
    "# train = add_value_to_segment(\n",
    "#     train,\n",
    "#     build_num=10,\n",
    "#     start_str=\"2024-06-01 00:00\",\n",
    "#     end_str=\"2024-07-04 07:00\",\n",
    "#     add_value=900\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf48435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_prev_next_day_avg(train: pd.DataFrame, build_num: int, start_str: str, end_str: str):\n",
    "    \"\"\"\n",
    "    ÌäπÏ†ï Í±¥Î¨ºÏùò ÏßÄÏ†ï Íµ¨Í∞ÑÏùÑ ÌïòÎ£® Ï†Ñ/ÌïòÎ£® Îí§ ÎèôÏùº ÏãúÍ∞ÑÎåÄÏùò ÌèâÍ∑† Í∞íÏúºÎ°ú Ï±ÑÏõÄ.\n",
    "    train['power']Ïóê ÎçÆÏñ¥ÏîÄ.\n",
    "    \"\"\"\n",
    "    train['date_time'] = pd.to_datetime(train['date_time'])\n",
    "    building_data = train[train['build_num'] == build_num].sort_values(by='date_time')\n",
    "\n",
    "    # ÎåÄÏÉÅ Íµ¨Í∞Ñ\n",
    "    target_start = pd.Timestamp(start_str)\n",
    "    target_end = pd.Timestamp(end_str)\n",
    "    target_mask = (building_data['date_time'] >= target_start) & (building_data['date_time'] <= target_end)\n",
    "    target_times = building_data.loc[target_mask, 'date_time']\n",
    "    if target_times.empty:\n",
    "        print(f\"‚ö†Ô∏è ÎåÄÏÉÅ Íµ¨Í∞Ñ({start_str}~{end_str}) Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå\")\n",
    "        return train\n",
    "\n",
    "    # ÌïòÎ£® Ï†Ñ/ÌïòÎ£® Îí§ ÎèôÏùº ÏãúÍ∞ÑÎåÄ Íµ¨Í∞Ñ\n",
    "    prev_day_mask = (building_data['date_time'] >= target_start - pd.Timedelta(days=1)) & (building_data['date_time'] <= target_end - pd.Timedelta(days=1))\n",
    "    next_day_mask = (building_data['date_time'] >= target_start + pd.Timedelta(days=1)) & (building_data['date_time'] <= target_end + pd.Timedelta(days=1))\n",
    "    prev_data = building_data.loc[prev_day_mask, ['date_time', 'power']]\n",
    "    next_data = building_data.loc[next_day_mask, ['date_time', 'power']]\n",
    "\n",
    "    if prev_data.empty and next_data.empty:\n",
    "        print(f\"‚ö†Ô∏è Ï∞∏Ï°∞ Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå({start_str}~{end_str})\")\n",
    "        return train\n",
    "\n",
    "    # ÌèâÍ∑† Ìå®ÌÑ¥ Í≥ÑÏÇ∞ (ÏûàÏúºÎ©¥ Ìï©Ï≥êÏÑú ÌèâÍ∑†)\n",
    "    ref_values = []\n",
    "    if not prev_data.empty:\n",
    "        ref_values.append(prev_data['power'].values)\n",
    "    if not next_data.empty:\n",
    "        ref_values.append(next_data['power'].values)\n",
    "    ref_mean = sum(ref_values) / len(ref_values)  # Îëê ÎÇ†Ïßú ÌèâÍ∑†\n",
    "\n",
    "    # Í∏∏Ïù¥Í∞Ä Îã§Î•¥Î©¥ ÎßûÏ∂∞ÏÑú Ï±ÑÏõÄ\n",
    "    ref_mean_series = pd.Series(ref_mean)\n",
    "    ref_mean_series = ref_mean_series.reindex(range(len(target_times)), method='nearest')\n",
    "\n",
    "    # ÎçÆÏñ¥Ïì∞Í∏∞\n",
    "    train.loc[\n",
    "        (train['build_num'] == build_num) & (train['date_time'] >= target_start) & (train['date_time'] <= target_end),\n",
    "        'power'\n",
    "    ] = ref_mean_series.values\n",
    "\n",
    "    return train\n",
    "\n",
    "train = fill_with_prev_next_day_avg(\n",
    "    train,\n",
    "    build_num=70,\n",
    "    start_str=\"2024-06-04 09:00\",\n",
    "    end_str=\"2024-06-05 09:00\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b689d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_power_with_holiday_pattern(train, build_num, date_ranges):\n",
    "    \"\"\"\n",
    "    ÌäπÏ†ï Í±¥Î¨ºÏùò ÏßÄÏ†ï ÎÇ†Ïßú Íµ¨Í∞Ñ Ï†ÑÎ†• ÏÇ¨Ïö©ÎüâÏùÑ\n",
    "    Ï†ÑÌõÑ holiday Ìå®ÌÑ¥(Í∞ôÏùÄ ÏãúÍ∞ÑÎåÄ ÌèâÍ∑†)ÏúºÎ°ú ÎåÄÏ≤¥ÌïòÎäî Ìï®Ïàò.\n",
    "\n",
    "    Parameters:\n",
    "        train (pd.DataFrame): Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "        build_num (int): Í±¥Î¨º Î≤àÌò∏\n",
    "        date_ranges (list of tuples): [(start_date, end_date), ...] ÌòïÏãùÏùò Íµ¨Í∞Ñ Î¶¨Ïä§Ìä∏ (Î¨∏ÏûêÏó¥ or Timestamp)\n",
    "    Returns:\n",
    "        pd.DataFrame: powerÍ∞Ä ÎçÆÏñ¥ÏîåÏõåÏßÑ ÏõêÎ≥∏ train DataFrame\n",
    "    \"\"\"\n",
    "    # Îç∞Ïù¥ÌÑ∞ Ï†ïÎ†¨ Î∞è ÏãúÍ∞Ñ Î≥ÄÌôò\n",
    "    train['date_time'] = pd.to_datetime(train['date_time'])\n",
    "    building_data = train[train['build_num'] == build_num].sort_values(by='date_time').copy()\n",
    "    building_data['hour'] = building_data['date_time'].dt.hour\n",
    "\n",
    "    # holiday ÎÇ†Ïßú\n",
    "    holiday_dates = building_data[building_data['holiday'] == 1]['date_time']\n",
    "\n",
    "    for start_date, end_date in date_ranges:\n",
    "        target_start = pd.Timestamp(start_date)\n",
    "        target_end = pd.Timestamp(end_date)\n",
    "\n",
    "        # Ï†ÑÌõÑ holiday Ï∂îÏ∂ú\n",
    "        prev_holiday = holiday_dates[holiday_dates < target_start].max()\n",
    "        next_holiday = holiday_dates[holiday_dates > target_end].min()\n",
    "        if pd.isna(prev_holiday) or pd.isna(next_holiday):\n",
    "            continue  # holiday ÏóÜÏúºÎ©¥ skip\n",
    "\n",
    "        # Ï†ÑÌõÑ holiday Ìå®ÌÑ¥\n",
    "        prev_pattern = building_data[building_data['date_time'].dt.date == prev_holiday.date()]\n",
    "        next_pattern = building_data[building_data['date_time'].dt.date == next_holiday.date()]\n",
    "        holiday_pattern = (prev_pattern.groupby('hour')['power'].mean() +\n",
    "                           next_pattern.groupby('hour')['power'].mean()) / 2\n",
    "\n",
    "        # ÎåÄÏ≤¥\n",
    "        target_mask = (building_data['date_time'] >= target_start) & (building_data['date_time'] <= target_end)\n",
    "        building_data.loc[target_mask, 'power'] = building_data.loc[target_mask].apply(\n",
    "            lambda row: holiday_pattern.loc[row['hour']] if row['hour'] in holiday_pattern.index else row['power'],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    # trainÏóê Î∞òÏòÅ\n",
    "    train.loc[building_data.index, 'power'] = building_data['power']\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f31084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def copy_pattern_by_days(\n",
    "    df,\n",
    "    build_num,\n",
    "    target_start,\n",
    "    target_end,\n",
    "    offset_days,          # Ïòà: -7(Ïù¥Ï†Ñ Ï£º), +7(Îã§Ïùå Ï£º), +3(3Ïùº Îí§) Îì±\n",
    "    col='power',\n",
    "    dt_col='date_time',\n",
    "    inplace=False\n",
    "):\n",
    "    \"\"\"\n",
    "    [target_start ~ target_end] Íµ¨Í∞ÑÏùò Í∞íÏùÑ\n",
    "    (offset_days ÎßåÌÅº Ïù¥ÎèôÌïú Íµ¨Í∞Ñ)Ïùò Ìå®ÌÑ¥ÏúºÎ°ú ÎçÆÏñ¥Ïì∞Í∏∞.\n",
    "    \"\"\"\n",
    "    _df = df if inplace else df.copy()\n",
    "\n",
    "    ts, te = pd.to_datetime(target_start), pd.to_datetime(target_end)\n",
    "    ss, se = ts + pd.Timedelta(days=offset_days), te + pd.Timedelta(days=offset_days)\n",
    "\n",
    "    m_src = (_df['build_num'] == build_num) & (_df[dt_col] >= ss) & (_df[dt_col] <= se)\n",
    "    m_tgt = (_df['build_num'] == build_num) & (_df[dt_col] >= ts) & (_df[dt_col] <= te)\n",
    "\n",
    "    src_vals = _df.loc[m_src].sort_values(dt_col)[col].values\n",
    "    tgt_idx  = _df.loc[m_tgt].sort_values(dt_col).index\n",
    "\n",
    "    if len(src_vals) == 0 or len(tgt_idx) == 0:\n",
    "        return _df  # ÏÜåÏä§/ÌÉÄÍ≤üÏù¥ ÏóÜÏúºÎ©¥ Í∑∏ÎåÄÎ°ú Î∞òÌôò\n",
    "\n",
    "    n = min(len(src_vals), len(tgt_idx))\n",
    "    _df.loc[tgt_idx[:n], col] = src_vals[:n]\n",
    "    return _df\n",
    "\n",
    "\n",
    "def batch_copy_patterns_by_days(\n",
    "    df,\n",
    "    jobs,                 # [(build_num, t_start, t_end, offset_days), ...] ÎòêÎäî dict Î¶¨Ïä§Ìä∏\n",
    "    col='power',\n",
    "    dt_col='date_time',\n",
    "    inplace=False,\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Ïó¨Îü¨ Í±¥ÏùÑ Ìïú Î≤àÏóê Ï≤òÎ¶¨ÌïòÎäî Î∞∞Ïπò Ìï®Ïàò.\n",
    "    jobs ÏõêÏÜå ÌòïÌÉú:\n",
    "      - ÌäúÌîå: (build_num, target_start, target_end, offset_days)\n",
    "      - ÎîïÏÖîÎÑàÎ¶¨: {\n",
    "            \"build_num\": ...,\n",
    "            \"target_start\": ...,\n",
    "            \"target_end\": ...,\n",
    "            # ÏïÑÎûò Ï§ë ÌïòÎÇò\n",
    "            \"offset_days\": ...,\n",
    "            \"week_offset\": ...  # ÏûàÏúºÎ©¥ 7*week_offsetÏúºÎ°ú Î≥ÄÌôò\n",
    "        }\n",
    "      ‚Äª offset_daysÍ∞Ä ÏûàÏúºÎ©¥ week_offsetÎ≥¥Îã§ Ïö∞ÏÑ†\n",
    "    \"\"\"\n",
    "    def _parse(job):\n",
    "        if isinstance(job, (list, tuple)) and len(job) == 4:\n",
    "            b, ts, te, od = job\n",
    "            return b, ts, te, od\n",
    "        if isinstance(job, dict):\n",
    "            b  = job['build_num']\n",
    "            ts = job['target_start']\n",
    "            te = job['target_end']\n",
    "            if 'offset_days' in job:\n",
    "                od = job['offset_days']\n",
    "            elif 'week_offset' in job:\n",
    "                od = 7 * job['week_offset']\n",
    "            else:\n",
    "                raise ValueError(\"dict jobÏóêÎäî 'offset_days' ÎòêÎäî 'week_offset' Ï§ë ÌïòÎÇòÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§.\")\n",
    "            return b, ts, te, od\n",
    "        raise ValueError(\"jobs Ìï≠Î™©ÏùÄ (build_num, start, end, offset_days) ÌäúÌîå ÎòêÎäî Ìï¥Îãπ ÌÇ§Î•º Í∞ÄÏßÑ dictÏó¨Ïïº Ìï©ÎãàÎã§.\")\n",
    "\n",
    "    _df = df if inplace else df.copy()\n",
    "\n",
    "    for job in jobs:\n",
    "        b, ts, te, od = _parse(job)\n",
    "        if verbose:\n",
    "            print(f\"[batch] build_num={b}, target=({ts}~{te}), offset_days={od}\")\n",
    "        _df = copy_pattern_by_days(\n",
    "            _df, b, ts, te, od, col=col, dt_col=dt_col, inplace=True\n",
    "        )\n",
    "    return _df\n",
    "\n",
    "\n",
    "jobs = [\n",
    "    (5, \"2024-08-04 00:00\", \"2024-08-04 23:00\", -7),\n",
    "    (6, \"2024-08-15 00:00\", \"2024-08-15 23:00\", -4),\n",
    "    (6, \"2024-08-16 00:00\", \"2024-08-16 23:00\", -7),\n",
    "    (6, \"2024-08-17 00:00\", \"2024-08-17 23:00\", -7),\n",
    "    (6, \"2024-08-18 00:00\", \"2024-08-18 23:00\", -7),\n",
    "    (7, \"2024-07-07 10:00\", \"2024-07-08 11:00\", -7),\n",
    "    (8,  \"2024-07-21 08:00\", \"2024-07-21 11:00\", -7),\n",
    "    (8,  \"2024-08-24 00:00\", \"2024-08-24 23:00\", -7),\n",
    "    (12, \"2024-07-21 00:00\", \"2024-07-21 23:00\", +7),\n",
    "    (12, \"2024-08-24 00:00\", \"2024-08-24 23:00\", -7),\n",
    "    (17, \"2024-06-25 15:00\", \"2024-06-26 09:00\", -7),\n",
    "    (20, \"2024-06-01 00:00\", \"2024-06-01 23:00\", +7),\n",
    "    (25, \"2024-07-04 12:00\", \"2024-07-04 14:00\", +7),\n",
    "    (26, \"2024-06-17 14:00\", \"2024-06-18 11:00\", -7),\n",
    "    (29, \"2024-06-15 22:00\", \"2024-06-15 23:00\", -7),\n",
    "    (29, \"2024-06-27 00:00\", \"2024-06-27 01:00\", -7),\n",
    "    (30, \"2024-08-04 00:00\", \"2024-08-04 23:00\", -1),\n",
    "    (30, \"2024-08-05 00:00\", \"2024-08-05 23:00\", -1),\n",
    "    (30, \"2024-08-07 00:00\", \"2024-08-07 23:00\", -1),\n",
    "    (40, \"2024-07-14 00:00\", \"2024-07-14 01:00\", -1),\n",
    "    (41, \"2024-06-22 01:00\", \"2024-06-22 04:00\", -7),\n",
    "    (41, \"2024-07-17 00:00\", \"2024-07-17 23:00\", -7),\n",
    "    (42, \"2024-07-17 00:00\", \"2024-07-17 23:00\", -1),\n",
    "    (43, \"2024-06-10 17:00\", \"2024-06-10 18:00\", -7),\n",
    "    (43, \"2024-08-12 16:00\", \"2024-08-12 17:00\", -7),\n",
    "    (43, \"2024-07-20 00:00\", \"2024-07-21 23:00\", -7)\n",
    "]\n",
    "\n",
    "train = batch_copy_patterns_by_days(train, jobs, col='power', dt_col='date_time', inplace=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64d8551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 203832/203832 [00:48<00:00, 4190.52it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 203832/203832 [00:49<00:00, 4134.05it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 203832/203832 [00:49<00:00, 4100.26it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 203832/203832 [00:50<00:00, 4038.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>build_num</th>\n",
       "      <th>date_time</th>\n",
       "      <th>temp</th>\n",
       "      <th>prec</th>\n",
       "      <th>wind</th>\n",
       "      <th>hum</th>\n",
       "      <th>isolation</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>power</th>\n",
       "      <th>use</th>\n",
       "      <th>area_1</th>\n",
       "      <th>area_2</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>solar_per_hour</th>\n",
       "      <th>CDH</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_wind</th>\n",
       "      <th>max_wind</th>\n",
       "      <th>min_hum</th>\n",
       "      <th>max_hum</th>\n",
       "      <th>mean_THI</th>\n",
       "      <th>mean_CDH</th>\n",
       "      <th>min_log_temp</th>\n",
       "      <th>max_log_temp</th>\n",
       "      <th>mean_WC</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20240601 00</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-01 00:00:00</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5794.80</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>17.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>53.788788</td>\n",
       "      <td>-53.0625</td>\n",
       "      <td>2.923162</td>\n",
       "      <td>3.250374</td>\n",
       "      <td>21.342341</td>\n",
       "      <td>11.353622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20240601 01</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-01 01:00:00</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5591.85</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>17.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>53.788788</td>\n",
       "      <td>-53.0625</td>\n",
       "      <td>2.923162</td>\n",
       "      <td>3.250374</td>\n",
       "      <td>21.342341</td>\n",
       "      <td>10.540611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20240601 02</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-01 02:00:00</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5338.17</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>53.788788</td>\n",
       "      <td>-53.0625</td>\n",
       "      <td>2.923162</td>\n",
       "      <td>3.250374</td>\n",
       "      <td>21.342341</td>\n",
       "      <td>9.252619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20240601 03</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-01 03:00:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4554.42</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-31.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>53.788788</td>\n",
       "      <td>-53.0625</td>\n",
       "      <td>2.923162</td>\n",
       "      <td>3.250374</td>\n",
       "      <td>21.342341</td>\n",
       "      <td>7.926321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20240601 04</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-01 04:00:00</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3602.25</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-39.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>53.788788</td>\n",
       "      <td>-53.0625</td>\n",
       "      <td>2.923162</td>\n",
       "      <td>3.250374</td>\n",
       "      <td>21.342341</td>\n",
       "      <td>7.884329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  build_num           date_time  temp  prec  wind   hum  \\\n",
       "0  1_20240601 00          1 2024-06-01 00:00:00  18.3   0.0   2.6  82.0   \n",
       "1  1_20240601 01          1 2024-06-01 01:00:00  18.3   0.0   2.7  82.0   \n",
       "2  1_20240601 02          1 2024-06-01 02:00:00  18.1   0.0   2.6  80.0   \n",
       "3  1_20240601 03          1 2024-06-01 03:00:00  18.0   0.0   2.6  81.0   \n",
       "4  1_20240601 04          1 2024-06-01 04:00:00  17.8   0.0   1.3  81.0   \n",
       "\n",
       "   isolation  sunshine    power use    area_1   area_2  hour  month  ...  \\\n",
       "0        0.0       0.0  5794.80  Ìò∏ÌÖî  82912.71  77586.0     0      6  ...   \n",
       "1        0.0       0.0  5591.85  Ìò∏ÌÖî  82912.71  77586.0     1      6  ...   \n",
       "2        0.0       0.0  5338.17  Ìò∏ÌÖî  82912.71  77586.0     2      6  ...   \n",
       "3        0.0       0.0  4554.42  Ìò∏ÌÖî  82912.71  77586.0     3      6  ...   \n",
       "4        0.0       0.0  3602.25  Ìò∏ÌÖî  82912.71  77586.0     4      6  ...   \n",
       "\n",
       "   dew_point  solar_per_hour   CDH  min_temp  max_temp  min_wind  max_wind  \\\n",
       "0       14.7             0.0  -7.7      17.6      24.8       1.2       3.9   \n",
       "1       14.7             0.0 -15.4      17.6      24.8       1.2       3.9   \n",
       "2       14.1             0.0 -23.3      17.6      24.8       1.2       3.9   \n",
       "3       14.2             0.0 -31.3      17.6      24.8       1.2       3.9   \n",
       "4       14.0             0.0 -39.5      17.6      24.8       1.2       3.9   \n",
       "\n",
       "   min_hum  max_hum   mean_THI  mean_CDH  min_log_temp  max_log_temp  \\\n",
       "0     36.0     85.0  53.788788  -53.0625      2.923162      3.250374   \n",
       "1     36.0     85.0  53.788788  -53.0625      2.923162      3.250374   \n",
       "2     36.0     85.0  53.788788  -53.0625      2.923162      3.250374   \n",
       "3     36.0     85.0  53.788788  -53.0625      2.923162      3.250374   \n",
       "4     36.0     85.0  53.788788  -53.0625      2.923162      3.250374   \n",
       "\n",
       "     mean_WC    z_score  \n",
       "0  21.342341  11.353622  \n",
       "1  21.342341  10.540611  \n",
       "2  21.342341   9.252619  \n",
       "3  21.342341   7.926321  \n",
       "4  21.342341   7.884329  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isolation = pd.pivot_table(train, values = 'isolation', index = ['build_num', 'hour', 'month'], aggfunc = np.mean).reset_index()\n",
    "sunshine = pd.pivot_table(train, values = 'sunshine', index = ['build_num', 'hour', 'month'], aggfunc = np.mean).reset_index()\n",
    "\n",
    "## Í≥µÌú¥Ïùº Î≥ÄÏàò Ï∂îÍ∞Ä\n",
    "train['holiday'] = train.apply(lambda x : 0 if x['weekday']<5 else 1, axis = 1)\n",
    "train.loc[('20240606'<=train.date_time)&(train.date_time<'20240607'),'holiday'] = 1\n",
    "train.loc[('20240815'<=train.date_time)&(train.date_time<'20240816'),'holiday'] = 1\n",
    "\n",
    "# Í∑úÏπô Ï†ïÏùò Ìï®Ïàò\n",
    "def apply_holiday_rules(row):\n",
    "    bn = row['build_num']\n",
    "    wd = row['weekday']\n",
    "    day = row['day']\n",
    "    week = (row['day'] - 1) // 7 + 1  # Î™áÏß∏ Ï£ºÏù∏ÏßÄ Í≥ÑÏÇ∞\n",
    "\n",
    "    # üìå Í∞úÎ≥Ñ Í∑úÏπô Ï†ÅÏö©\n",
    "    if bn == 2:   # ÏÉÅÏö©: ÌÜ†ÏöîÏùº Ïâº ‚Üí holiday = 1 if ÌÜ†ÏöîÏùº else 0\n",
    "        return 1 if wd == 5 else 0\n",
    "    elif bn == 7:   # Í±¥Î¨ºÍ∏∞ÌÉÄ: ÏùºÏöîÏùº Ïâº\n",
    "        return 1 if wd == 6 else 0\n",
    "    elif bn == 18:  # Î∞±ÌôîÏ†ê: ÏùºÏöîÏùº Ïâº\n",
    "        return 1 if wd == 6 else 0\n",
    "    # elif bn == 19:  # Î∞±ÌôîÏ†ê: ÎëòÏß∏Ï£º ÏõîÏöîÏùº Ïâº\n",
    "    #     return 1 if wd == 0 and week == 2 else 0\n",
    "    elif bn == 25:  # ÏïÑÌååÌä∏: ÌÜ†ÏöîÏùºÏóê Ï†ÅÍ≤å ÏîÄ (ÌèâÏùºÎ°ú Í∞ÑÏ£º)\n",
    "        return 0\n",
    "    # elif bn == 26:  # Í±¥Î¨ºÍ∏∞ÌÉÄ: Ï£ºÎßêÏóê Îçî ÏîÄ ‚Üí ÌèâÏùºÎ°ú Í∞ÑÏ£º\n",
    "    #     return 0 if wd in [5, 6] else 1\n",
    "    elif bn == 26:  # Í±¥Î¨ºÍ∏∞ÌÉÄ: Ï£ºÎßêÏóê Îçî ÏîÄ ‚Üí ÌèâÏùºÎ°ú Í∞ÑÏ£º\n",
    "        return 0\n",
    "    elif bn == 27:  # Î∞±ÌôîÏ†ê: ÎëòÏß∏, ÎÑ∑Ïß∏Ï£º ÏùºÏöîÏùº Ïâº\n",
    "        return 1 if wd == 6 and week in [2, 4] else 0\n",
    "    elif bn == 29:  # Î∞±ÌôîÏ†ê: Îß§Îã¨ 10Ïùº Ïâº\n",
    "        return 1 if day == 10 else 0\n",
    "    elif bn == 31:  # ÏïÑÌååÌä∏: Ìú¥Ïùº ÏóÜÏùå ‚Üí ÌèâÏùº Ï∑®Í∏â\n",
    "        return 0\n",
    "    elif bn == 32:  # Î∞±ÌôîÏ†ê: ÎëòÏß∏, ÎÑ∑Ïß∏Ï£º ÏõîÏöîÏùº Ïâº\n",
    "        return 1 if wd == 0 and week in [2, 4] else 0\n",
    "    elif bn == 34:  # Î∞±ÌôîÏ†ê: Ìú¥Ïùº ÏóÜÏùå ‚Üí ÌèâÏùº Ï∑®Í∏â\n",
    "        return 0\n",
    "    elif bn == 35:  # Ï†ÑÌôîÍµ≠: Ìú¥Ïùº ÏóÜÏùå -> ÌèâÏùº Ï∑®Í∏â\n",
    "        return 0\n",
    "    elif bn == 36:  # Ï†ÑÌôîÍµ≠: Ìú¥Ïùº ÏóÜÏùå -> ÌèâÏùº Ï∑®Í∏â\n",
    "        return 1 if wd in [5, 6] else 0\n",
    "    elif bn == 40:  # Î∞±ÌôîÏ†ê: ÎëòÏß∏, ÎÑ∑Ïß∏Ï£º ÏõîÏöîÏùº Ïâº\n",
    "        return 1 if wd == 6 and week in [2, 4] else 0\n",
    "    elif bn == 41:\n",
    "        return 0\n",
    "    # elif bn == 45:\n",
    "    #     return 1 if day == 10 else 0\n",
    "    elif bn == 54:\n",
    "        return 0\n",
    "    elif bn == 57:\n",
    "        return 0\n",
    "    elif bn == 58:\n",
    "        return 0\n",
    "    elif bn == 59:\n",
    "        return 1 if wd == 6 and week in [2, 4] else 0\n",
    "    elif bn == 61:\n",
    "        return 0\n",
    "    elif bn == 63:\n",
    "        return 1 if wd == 6 and week in [2, 4] else 0\n",
    "    elif bn in [97]:  # ÌÜ†ÏöîÏùºÏâº\n",
    "        return 1 if wd == 5 else 0\n",
    "    elif bn in [1,4,9,10,11,19]:\n",
    "        return 0\n",
    "    elif bn in [10,28,30,33,45,65,70,71,73,74,76,77,78,79,82,84,85,88,89,91,92,93,95,96,98,99,100]:\n",
    "        return 0\n",
    "    else:\n",
    "        # Í∏∞Î≥∏ Í∑úÏπô Ïú†ÏßÄ\n",
    "        return row['holiday']\n",
    "\n",
    "# Í∑úÏπô Ï†ÅÏö©\n",
    "train['holiday'] = train.apply(apply_holiday_rules, axis=1)\n",
    "\n",
    "single_day_holidays = [\n",
    "    (19, '2024-06-10'),\n",
    "    (19, '2024-07-08'),\n",
    "    (19, '2024-08-19'),\n",
    "    (23, '2024-06-07'),\n",
    "    (23, '2024-08-16'),\n",
    "    (29, '2024-06-23'),\n",
    "    (29, '2024-07-28'),\n",
    "    (45, '2024-06-10'),\n",
    "    (45, '2024-07-08'),\n",
    "    (45, '2024-08-19'),\n",
    "    (49, '2024-08-22'),\n",
    "    (54, '2024-06-17'),\n",
    "    (54, '2024-07-01'),\n",
    "    (54, '2024-08-19'),\n",
    "    (56, '2024-06-07'),\n",
    "    (56, '2024-08-16'),\n",
    "    (67, '2024-07-26'),\n",
    "    (74, '2024-06-17'),\n",
    "    (74, '2024-07-01'),\n",
    "    (79, '2024-06-17'),\n",
    "    (79, '2024-07-01'),\n",
    "    (79, '2024-08-19'),\n",
    "    (94, '2024-06-07'),\n",
    "    (94, '2024-08-16'),\n",
    "    (95, '2024-07-08'),\n",
    "    (95, '2024-08-05'),\n",
    "]\n",
    "\n",
    "for build_num, date_str in single_day_holidays:\n",
    "    target_date = pd.to_datetime(date_str).date()  # ÎÇ†ÏßúÎßå ÎπÑÍµê\n",
    "    train.loc[\n",
    "        (train['build_num'] == build_num) &\n",
    "        (train['date_time'].dt.date == target_date),\n",
    "        'holiday'\n",
    "    ] = 1\n",
    "\n",
    "single_day_no_holiday = [\n",
    "    (67, '2024-06-06')\n",
    "]\n",
    "\n",
    "for build_num, date_str in single_day_no_holiday:\n",
    "    target_date = pd.to_datetime(date_str).date()  # ÎÇ†ÏßúÎßå ÎπÑÍµê\n",
    "    train.loc[\n",
    "        (train['build_num'] == build_num) &\n",
    "        (train['date_time'].dt.date == target_date),\n",
    "        'holiday'\n",
    "    ] = 0\n",
    "\n",
    "date_ranges = [\n",
    "    ('2024-07-26 00:00:00', '2024-07-26 23:59:59'),\n",
    "]\n",
    "train = fill_power_with_holiday_pattern(train, build_num=67, date_ranges=date_ranges)\n",
    "\n",
    "## Í±¥Î¨ºÎ≥Ñ, ÏöîÏùºÎ≥Ñ, ÏãúÍ∞ÑÎ≥Ñ Ï†ÑÎ†•ÏÜåÎπÑÎüâ ÌèâÍ∑†\n",
    "power_mean_1 = pd.pivot_table(train, values = 'power', index = ['build_num', 'hour', 'weekday'], aggfunc = np.mean).reset_index()\n",
    "tqdm.pandas()\n",
    "train['target_mean_1'] = train.progress_apply(lambda x : power_mean_1.loc[(power_mean_1.build_num == x['build_num']) & (power_mean_1.hour == x['hour']) & (power_mean_1.weekday == x['weekday']) ,'power'].values[0], axis = 1)\n",
    "\n",
    "## Í±¥Î¨ºÎ≥Ñ, ÏöîÏùºÎ≥Ñ, ÏãúÍ∞ÑÎ≥Ñ Ï†ÑÎ†•ÏÜåÎπÑÎüâ ÌëúÏ§ÄÌé∏Ï∞®\n",
    "power_std_1 = pd.pivot_table(train, values = 'power', index = ['build_num', 'hour', 'weekday'], aggfunc = np.std).reset_index()\n",
    "tqdm.pandas()\n",
    "train['target_std_1'] = train.progress_apply(lambda x : power_std_1.loc[(power_std_1.build_num == x['build_num']) & (power_std_1.hour == x['hour']) & (power_std_1.weekday == x['weekday']) ,'power'].values[0], axis = 1)\n",
    "\n",
    "## Í±¥Î¨ºÎ≥Ñ, ÏöîÏùºÎ≥Ñ, ÏãúÍ∞ÑÎ≥Ñ Ï†ÑÎ†•ÏÜåÎπÑÎüâ ÌëúÏ§ÄÌé∏Ï∞®\n",
    "power_min_1 = pd.pivot_table(train, values = 'power', index = ['build_num', 'hour', 'weekday'], aggfunc = np.min).reset_index()\n",
    "tqdm.pandas()\n",
    "train['target_min_1'] = train.progress_apply(lambda x : power_min_1.loc[(power_min_1.build_num == x['build_num']) & (power_min_1.hour == x['hour']) & (power_min_1.weekday == x['weekday']) ,'power'].values[0], axis = 1)\n",
    "\n",
    "## Í±¥Î¨ºÎ≥Ñ, ÏöîÏùºÎ≥Ñ, ÏãúÍ∞ÑÎ≥Ñ Ï†ÑÎ†•ÏÜåÎπÑÎüâ ÌëúÏ§ÄÌé∏Ï∞®\n",
    "power_max_1 = pd.pivot_table(train, values = 'power', index = ['build_num', 'hour', 'weekday'], aggfunc = np.max).reset_index()\n",
    "tqdm.pandas()\n",
    "train['target_max_1'] = train.progress_apply(lambda x : power_max_1.loc[(power_max_1.build_num == x['build_num']) & (power_max_1.hour == x['hour']) & (power_max_1.weekday == x['weekday']) ,'power'].values[0], axis = 1)\n",
    "\n",
    "## https://dacon.io/competitions/official/235680/codeshare/2366?page=1&dtype=recent\n",
    "train['sin_hour'] = np.sin(2*np.pi*train.hour/24)\n",
    "train['cos_hour'] = np.cos(2*np.pi*train.hour/24)\n",
    "train['sin_date'] = -np.sin(2 * np.pi * (train['month']+train['day']/31)/12)\n",
    "train['cos_date'] = -np.cos(2 * np.pi * (train['month']+train['day']/31)/12)\n",
    "train['sin_weekday'] = -np.sin(2 * np.pi * (train['weekday']+1)/7.0)\n",
    "train['cos_weekday'] = -np.cos(2 * np.pi * (train['weekday']+1)/7.0)\n",
    "\n",
    "#summer_sin, cos\n",
    "train['summer_sin'] = train['date_time'].apply(summer_sin)\n",
    "train['summer_cos'] = train['date_time'].apply(summer_cos)\n",
    "\n",
    "## ÌôîÏî® Ïò®ÎèÑ\n",
    "train['temp_F'] = (train['temp'] * 9/5) + 32\n",
    "\n",
    "## Ï≤¥Í∞ê Ïò®ÎèÑ\n",
    "train['temp2'] = 13.12 + 0.6215*train['temp'] - 11.37*(train['wind']*3.6)**0.16 + 0.3965*(train['wind']*3.6)**0.16*train['temp']\n",
    "\n",
    "## https://dacon.io/competitions/official/235736/codeshare/2743?page=1&dtype=recent\n",
    "train['THI'] = 9/5*train['temp'] - 0.55*(1-train['hum']/100)*(9/5*train['hum']-26)+32\n",
    "train['WC']=13.12+0.6215*train['temp']-13.947*train['wind']**0.16+0.486*train['temp']*train['wind']**0.16\n",
    "\n",
    "train['is_rain'] = (train['prec'] > 0).astype(int)\n",
    "train['log_temp'] = np.log1p(train['temp'])\n",
    "train['wind_power'] = train['wind'] ** 2\n",
    "train['dew_point'] = train['temp'] - (100 - train['hum']) / 5\n",
    "train['solar_per_hour'] = train['isolation'] / (train['sunshine'] + 1e-3)\n",
    "def CDH(xs):\n",
    "    ys = []\n",
    "    for i in range(len(xs)):\n",
    "        if i < 11:\n",
    "            ys.append(np.sum(xs[:(i+1)]-26))\n",
    "        else:\n",
    "            ys.append(np.sum(xs[(i-11):(i+1)]-26))\n",
    "    return np.array(ys)\n",
    "\n",
    "cdhs = np.array([])\n",
    "for num in range(1,101,1):\n",
    "    temp = train[train['build_num'] == num]\n",
    "    cdh = CDH(temp['temp'].values)\n",
    "    cdhs = np.concatenate([cdhs, cdh])\n",
    "train['CDH'] = cdhs\n",
    "\n",
    "## min temperature\n",
    "train = train.merge(train.groupby(['build_num','date'])['temp'].min().reset_index().rename(columns = {'temp':'min_temp'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## max temperature\n",
    "train = train.merge(train.groupby(['build_num','date'])['temp'].max().reset_index().rename(columns = {'temp':'max_temp'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## min windspeed\n",
    "train = train.merge(train.groupby(['build_num','date'])['wind'].min().reset_index().rename(columns = {'wind':'min_wind'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## max windspeed\n",
    "train = train.merge(train.groupby(['build_num','date'])['wind'].max().reset_index().rename(columns = {'wind':'max_wind'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## min humidity\n",
    "train = train.merge(train.groupby(['build_num','date'])['hum'].min().reset_index().rename(columns = {'hum':'min_hum'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## max humidity\n",
    "train = train.merge(train.groupby(['build_num','date'])['hum'].max().reset_index().rename(columns = {'hum':'max_hum'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## mean THI\n",
    "train = train.merge(train.groupby(['build_num','date'])['THI'].mean().reset_index().rename(columns = {'THI':'mean_THI'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## mean CDH\n",
    "train = train.merge(train.groupby(['build_num','date'])['CDH'].mean().reset_index().rename(columns = {'CDH':'mean_CDH'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "train = train.merge(train.groupby(['build_num','date'])['log_temp'].min().reset_index().rename(columns = {'log_temp':'min_log_temp'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "train = train.merge(train.groupby(['build_num','date'])['log_temp'].max().reset_index().rename(columns = {'log_temp':'max_log_temp'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "train = train.merge(train.groupby(['build_num','date'])['WC'].mean().reset_index().rename(columns = {'WC':'mean_WC'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "train['z_score'] = train['target_mean_1'] / train['target_std_1']\n",
    "train.drop(columns=['date','day','weekday'], inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "376440d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16800/16800 [00:03<00:00, 4423.81it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16800/16800 [00:03<00:00, 4470.59it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16800/16800 [00:04<00:00, 4115.90it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16800/16800 [00:04<00:00, 4116.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16800/16800 [00:03<00:00, 4228.00it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16800/16800 [00:03<00:00, 4223.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>build_num</th>\n",
       "      <th>date_time</th>\n",
       "      <th>temp</th>\n",
       "      <th>prec</th>\n",
       "      <th>wind</th>\n",
       "      <th>hum</th>\n",
       "      <th>use</th>\n",
       "      <th>area_1</th>\n",
       "      <th>area_2</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>holiday</th>\n",
       "      <th>isolation</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>...</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>solar_per_hour</th>\n",
       "      <th>CDH</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_wind</th>\n",
       "      <th>max_wind</th>\n",
       "      <th>min_hum</th>\n",
       "      <th>max_hum</th>\n",
       "      <th>mean_THI</th>\n",
       "      <th>mean_CDH</th>\n",
       "      <th>min_log_temp</th>\n",
       "      <th>max_log_temp</th>\n",
       "      <th>mean_WC</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20240825 00</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-25 00:00:00</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>69.47355</td>\n",
       "      <td>18.695833</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>3.514526</td>\n",
       "      <td>30.722386</td>\n",
       "      <td>7.365460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20240825 01</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-25 01:00:00</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>69.47355</td>\n",
       "      <td>18.695833</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>3.514526</td>\n",
       "      <td>30.722386</td>\n",
       "      <td>6.376051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20240825 02</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-25 02:00:00</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>69.47355</td>\n",
       "      <td>18.695833</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>3.514526</td>\n",
       "      <td>30.722386</td>\n",
       "      <td>6.212821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20240825 03</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-25 03:00:00</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>69.47355</td>\n",
       "      <td>18.695833</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>3.514526</td>\n",
       "      <td>30.722386</td>\n",
       "      <td>6.006666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20240825 04</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-25 04:00:00</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Ìò∏ÌÖî</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>69.47355</td>\n",
       "      <td>18.695833</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>3.514526</td>\n",
       "      <td>30.722386</td>\n",
       "      <td>11.326145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  build_num           date_time  temp  prec  wind   hum use  \\\n",
       "0  1_20240825 00          1 2024-08-25 00:00:00  26.5   0.0   0.7  80.0  Ìò∏ÌÖî   \n",
       "1  1_20240825 01          1 2024-08-25 01:00:00  26.1   0.0   0.0  80.0  Ìò∏ÌÖî   \n",
       "2  1_20240825 02          1 2024-08-25 02:00:00  25.9   0.0   0.3  83.0  Ìò∏ÌÖî   \n",
       "3  1_20240825 03          1 2024-08-25 03:00:00  25.7   0.0   1.1  83.0  Ìò∏ÌÖî   \n",
       "4  1_20240825 04          1 2024-08-25 04:00:00  25.5   0.0   1.0  86.0  Ìò∏ÌÖî   \n",
       "\n",
       "     area_1   area_2  hour  month  holiday  isolation  sunshine  ...  \\\n",
       "0  82912.71  77586.0     0      8        0        0.0       0.0  ...   \n",
       "1  82912.71  77586.0     1      8        0        0.0       0.0  ...   \n",
       "2  82912.71  77586.0     2      8        0        0.0       0.0  ...   \n",
       "3  82912.71  77586.0     3      8        0        0.0       0.0  ...   \n",
       "4  82912.71  77586.0     4      8        0        0.0       0.0  ...   \n",
       "\n",
       "   dew_point  solar_per_hour  CDH  min_temp  max_temp  min_wind  max_wind  \\\n",
       "0       22.5             0.0  0.5      25.0      32.6       0.0       3.6   \n",
       "1       22.1             0.0  0.6      25.0      32.6       0.0       3.6   \n",
       "2       22.5             0.0  0.5      25.0      32.6       0.0       3.6   \n",
       "3       22.3             0.0  0.2      25.0      32.6       0.0       3.6   \n",
       "4       22.7             0.0 -0.3      25.0      32.6       0.0       3.6   \n",
       "\n",
       "   min_hum  max_hum  mean_THI   mean_CDH  min_log_temp  max_log_temp  \\\n",
       "0     60.0     90.0  69.47355  18.695833      3.258097      3.514526   \n",
       "1     60.0     90.0  69.47355  18.695833      3.258097      3.514526   \n",
       "2     60.0     90.0  69.47355  18.695833      3.258097      3.514526   \n",
       "3     60.0     90.0  69.47355  18.695833      3.258097      3.514526   \n",
       "4     60.0     90.0  69.47355  18.695833      3.258097      3.514526   \n",
       "\n",
       "     mean_WC    z_score  \n",
       "0  30.722386   7.365460  \n",
       "1  30.722386   6.376051  \n",
       "2  30.722386   6.212821  \n",
       "3  30.722386   6.006666  \n",
       "4  30.722386  11.326145  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = pd.read_csv('./data/test.csv')\n",
    "# train setÍ≥º ÎèôÏùºÌïú Ï†ÑÏ≤òÎ¶¨ Í≥ºÏ†ï\n",
    "test['ÏùºÏãú'] = pd.to_datetime(test['ÏùºÏãú'])\n",
    "cols = ['num_date_time', 'build_num', 'date_time', 'temp' , 'prec', 'wind', 'hum', 'use', 'area_1', 'area_2']\n",
    "test.columns = cols\n",
    "\n",
    "# ÏãúÍ∞Ñ Í¥ÄÎ†® Î≥ÄÏàòÎì§ ÏÉùÏÑ±\n",
    "date = pd.to_datetime(test.date_time)\n",
    "test['date'] = date.dt.date\n",
    "test['hour'] = date.dt.hour\n",
    "test['day'] = date.dt.day\n",
    "test['weekday'] = date.dt.weekday\n",
    "test['month'] = date.dt.month\n",
    "\n",
    "test['holiday'] = test.apply(lambda x : 0 if x['weekday']<5 else 1, axis = 1)\n",
    "test['holiday'] = test.apply(apply_holiday_rules, axis=1)\n",
    "\n",
    "# for k, nums in CLUSTER.items():\n",
    "#     test.loc[test.build_num.isin(nums), 'cluster'] = k\n",
    "\n",
    "## ÏùºÏ°∞\n",
    "tqdm.pandas()\n",
    "test['isolation'] = np.round(test.progress_apply(lambda x : isolation.loc[(isolation.build_num == x['build_num']) & (isolation.hour == x['hour']) & (isolation.month == x['month']) ,'isolation'].values[0], axis = 1), 1)\n",
    "\n",
    "## ÏùºÏÇ¨\n",
    "tqdm.pandas()\n",
    "test['sunshine'] = np.round(test.progress_apply(lambda x : sunshine.loc[(sunshine.build_num == x['build_num']) & (sunshine.hour == x['hour']) & (sunshine.month == x['month']) ,'sunshine'].values[0], axis = 1), 2)\n",
    "\n",
    "## Í±¥Î¨ºÎ≥Ñ, ÏöîÏùºÎ≥Ñ, ÏãúÍ∞ÑÎ≥Ñ Ï†ÑÎ†•ÏÜåÎπÑÎüâ ÌèâÍ∑†\n",
    "tqdm.pandas()\n",
    "test['target_mean_1'] = test.progress_apply(lambda x : power_mean_1.loc[(power_mean_1.build_num == x['build_num']) & (power_mean_1.hour == x['hour']) & (power_mean_1.weekday == x['weekday']) ,'power'].values[0], axis = 1)\n",
    "\n",
    "## Í±¥Î¨ºÎ≥Ñ, ÏöîÏùºÎ≥Ñ, ÏãúÍ∞ÑÎ≥Ñ Ï†ÑÎ†•ÏÜåÎπÑÎüâ ÌëúÏ§ÄÌé∏Ï∞®\n",
    "tqdm.pandas()\n",
    "test['target_std_1'] = test.progress_apply(lambda x : power_std_1.loc[(power_std_1.build_num == x['build_num']) & (power_std_1.hour == x['hour']) & (power_std_1.weekday == x['weekday']) ,'power'].values[0], axis = 1)\n",
    "\n",
    "tqdm.pandas()\n",
    "test['target_min_1'] = test.progress_apply(lambda x : power_min_1.loc[(power_min_1.build_num == x['build_num']) & (power_min_1.hour == x['hour']) & (power_min_1.weekday == x['weekday']) ,'power'].values[0], axis = 1)\n",
    "\n",
    "tqdm.pandas()\n",
    "test['target_max_1'] = test.progress_apply(lambda x : power_max_1.loc[(power_max_1.build_num == x['build_num']) & (power_max_1.hour == x['hour']) & (power_max_1.weekday == x['weekday']) ,'power'].values[0], axis = 1)\n",
    "\n",
    "test['sin_hour'] = np.sin(2*np.pi*test.hour/24)\n",
    "test['cos_hour'] = np.cos(2*np.pi*test.hour/24)\n",
    "test['sin_date'] = -np.sin(2 * np.pi * (test['month']+test['day']/31)/12)\n",
    "test['cos_date'] = -np.cos(2 * np.pi * (test['month']+test['day']/31)/12)\n",
    "test['sin_weekday'] = -np.sin(2 * np.pi * (test['weekday']+1)/7.0)\n",
    "test['cos_weekday'] = -np.cos(2 * np.pi * (test['weekday']+1)/7.0)\n",
    "\n",
    "#summer_sin, cos\n",
    "test['summer_sin'] = test['date_time'].apply(summer_sin)\n",
    "test['summer_cos'] = test['date_time'].apply(summer_cos)\n",
    "\n",
    "## ÌôîÏî® Ïò®ÎèÑ\n",
    "test['temp_F'] = (test['temp'] * 9/5) + 32\n",
    "\n",
    "## Ï≤¥Í∞ê Ïò®ÎèÑ\n",
    "test['temp2'] = 13.12 + 0.6215*test['temp'] - 11.37*(test['wind']*3.6)**0.16 + 0.3965*(test['wind']*3.6)**0.16*test['temp']\n",
    "\n",
    "test['THI'] = 9/5*test['temp'] - 0.55*(1-test['hum']/100)*(9/5*test['hum']-26)+32\n",
    "test['WC']=13.12+0.6215*test['temp']-13.947*test['wind']**0.16+0.486*test['temp']*test['wind']**0.16\n",
    "\n",
    "test['is_rain'] = (test['prec'] > 0).astype(int)\n",
    "test['log_temp'] = np.log1p(test['temp'])\n",
    "test['wind_power'] = test['wind'] ** 2\n",
    "test['dew_point'] = test['temp'] - (100 - test['hum']) / 5\n",
    "test['solar_per_hour'] = test['isolation'] / (test['sunshine'] + 1e-3)\n",
    "cdhs = np.array([])\n",
    "for num in range(1,101,1):\n",
    "    temp = test[test['build_num'] == num]\n",
    "    cdh = CDH(temp['temp'].values)\n",
    "    cdhs = np.concatenate([cdhs, cdh])\n",
    "test['CDH'] = cdhs\n",
    "\n",
    "## min temperature\n",
    "test = test.merge(test.groupby(['build_num','date'])['temp'].min().reset_index().rename(columns = {'temp':'min_temp'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## max temperature\n",
    "test = test.merge(test.groupby(['build_num','date'])['temp'].max().reset_index().rename(columns = {'temp':'max_temp'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## min windspeed\n",
    "test = test.merge(test.groupby(['build_num','date'])['wind'].min().reset_index().rename(columns = {'wind':'min_wind'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## max windspeed\n",
    "test = test.merge(test.groupby(['build_num','date'])['wind'].max().reset_index().rename(columns = {'wind':'max_wind'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## min humidity\n",
    "test = test.merge(test.groupby(['build_num','date'])['hum'].min().reset_index().rename(columns = {'hum':'min_hum'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## max humidity\n",
    "test = test.merge(test.groupby(['build_num','date'])['hum'].max().reset_index().rename(columns = {'hum':'max_hum'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## mean THI\n",
    "test = test.merge(test.groupby(['build_num','date'])['THI'].mean().reset_index().rename(columns = {'THI':'mean_THI'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "## mean CDH\n",
    "test = test.merge(test.groupby(['build_num','date'])['CDH'].mean().reset_index().rename(columns = {'CDH':'mean_CDH'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "test = test.merge(test.groupby(['build_num','date'])['log_temp'].min().reset_index().rename(columns = {'log_temp':'min_log_temp'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "test = test.merge(test.groupby(['build_num','date'])['log_temp'].max().reset_index().rename(columns = {'log_temp':'max_log_temp'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "test = test.merge(test.groupby(['build_num','date'])['WC'].mean().reset_index().rename(columns = {'WC':'mean_WC'}), on = ['build_num','date'], how = 'left')\n",
    "\n",
    "test['z_score'] = test['target_mean_1'] / test['target_std_1']\n",
    "# test.drop(['date_time','date','day','weekday'], axis = 1, inplace = True)\n",
    "test.drop(['date','day','weekday'], axis = 1, inplace = True)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa4dc6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['hum'] = test['hum'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0af6d5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IDC(Ï†ÑÌôîÍµ≠)': 0, 'Í±¥Î¨ºÍ∏∞ÌÉÄ': 1, 'Í≥µÍ≥µ': 2, 'Î∞±ÌôîÏ†ê': 3, 'Î≥ëÏõê': 4, 'ÏÉÅÏö©': 5, 'ÏïÑÌååÌä∏': 6, 'Ïó∞Íµ¨ÏÜå': 7, 'ÌïôÍµê': 8, 'Ìò∏ÌÖî': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder ÏÉùÏÑ±\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit_transform: trainÏóê ÎåÄÌï¥ Î†àÏù¥Î∏î Ïù∏ÏΩîÎî©\n",
    "train['use'] = le.fit_transform(train['use'])\n",
    "test['use'] = le.transform(test['use'])\n",
    "\n",
    "# ÏòàÏãú: 'Ìò∏ÌÖî' ‚Üí 2, 'Î≥ëÏõê' ‚Üí 1 Ïù¥Îü∞ ÏãùÏúºÎ°ú Î≥ÄÌôòÎê®\n",
    "print(dict(zip(le.classes_, le.transform(le.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c389679",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./data/train_p_final2.csv', index=False)\n",
    "test.to_csv('./data/test_p_final2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
